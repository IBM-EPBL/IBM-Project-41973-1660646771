{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
    "Image Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "Loading Data and performing Data Augmentation\n",
    "x_train=train_datagen.flow_from_directory(r'/content/drive/MyDrive/ibm-nutrition-analyser/TRAIN_SET',target_size=(64,64),batch_size=32,class_mode='sparse')\n",
    "x_test=train_datagen.flow_from_directory(r'/content/drive/MyDrive/ibm-nutrition-analyser/TEST_SET',target_size=(64,64),batch_size=32,class_mode='sparse')\n",
    "Found 4119 images belonging to 5 classes.\n",
    "Found 929 images belonging to 5 classes.\n",
    "print(x_train.class_indices)\n",
    "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
    "print(x_test.class_indices)\n",
    "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
    "from collections import Counter as c\n",
    "c(x_train .labels)\n",
    "Counter({0: 996, 1: 1354, 2: 1019, 3: 275, 4: 475})\n",
    "Importing necessasry library\n",
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "Initializing The Model\n",
    "model = Sequential()\n",
    "Creating the model\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "classifier.summary()\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 5)                 645       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,733\n",
    "Trainable params: 813,733\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Compiling the model\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "Fitting the model\n",
    "classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=10, validation_data=x_test,validation_steps = len(x_test))\n",
    "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
    "  This is separate from the ipykernel package so we can avoid doing imports until\n",
    "Epoch 1/10\n",
    "129/129 [==============================] - 1192s 9s/step - loss: 0.6981 - accuracy: 0.7312 - val_loss: 0.6113 - val_accuracy: 0.7470\n",
    "Epoch 2/10\n",
    "129/129 [==============================] - 39s 300ms/step - loss: 0.4519 - accuracy: 0.8267 - val_loss: 0.5630 - val_accuracy: 0.7761\n",
    "Epoch 3/10\n",
    "129/129 [==============================] - 37s 286ms/step - loss: 0.3904 - accuracy: 0.8536 - val_loss: 0.4508 - val_accuracy: 0.8224\n",
    "Epoch 4/10\n",
    "129/129 [==============================] - 37s 286ms/step - loss: 0.3631 - accuracy: 0.8653 - val_loss: 0.4773 - val_accuracy: 0.8181\n",
    "Epoch 5/10\n",
    "129/129 [==============================] - 37s 289ms/step - loss: 0.3238 - accuracy: 0.8755 - val_loss: 0.4213 - val_accuracy: 0.8407\n",
    "Epoch 6/10\n",
    "129/129 [==============================] - 38s 294ms/step - loss: 0.3063 - accuracy: 0.8844 - val_loss: 0.3872 - val_accuracy: 0.8558\n",
    "Epoch 7/10\n",
    "129/129 [==============================] - 39s 304ms/step - loss: 0.2774 - accuracy: 0.8934 - val_loss: 0.3918 - val_accuracy: 0.8579\n",
    "Epoch 8/10\n",
    "129/129 [==============================] - 37s 286ms/step - loss: 0.2752 - accuracy: 0.8937 - val_loss: 0.4671 - val_accuracy: 0.8256\n",
    "Epoch 9/10\n",
    "129/129 [==============================] - 37s 288ms/step - loss: 0.2678 - accuracy: 0.8992 - val_loss: 0.3788 - val_accuracy: 0.8515\n",
    "Epoch 10/10\n",
    "129/129 [==============================] - 37s 287ms/step - loss: 0.2651 - accuracy: 0.8980 - val_loss: 0.4373 - val_accuracy: 0.8310\n",
    "Saving the model\n",
    "classifier.save('nutrition.h5')\n",
    "Testing the Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img(\"/content/drive/MyDrive/ibm-nutrition-analyser/TEST_SET/APPLES/n07740461_9461.jpg\",target_size= (64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "pred = classifier.predict(x)\n",
    "pred\n",
    "1/1 [==============================] - 0s 99ms/step\n",
    "array([[1., 0., 0., 0., 0.]], dtype=float32)\n",
    "index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
    "index[np.argmax(pred)]\n",
    "'APPLES'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
