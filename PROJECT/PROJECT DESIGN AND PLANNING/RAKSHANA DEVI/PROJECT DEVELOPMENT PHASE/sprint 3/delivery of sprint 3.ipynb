{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
    "Image Data Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "Loading Data and performing Data Augmentation\n",
    "x_train=train_datagen.flow_from_directory(r'/content/drive/MyDrive/ibm-nutrition-analyser/TRAIN_SET',target_size=(64,64),batch_size=32,class_mode='sparse')\n",
    "x_test=train_datagen.flow_from_directory(r'/content/drive/MyDrive/ibm-nutrition-analyser/TEST_SET',target_size=(64,64),batch_size=32,class_mode='sparse')\n",
    "Found 4119 images belonging to 5 classes.\n",
    "Found 929 images belonging to 5 classes.\n",
    "print(x_train.class_indices)\n",
    "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
    "print(x_test.class_indices)\n",
    "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n",
    "from collections import Counter as c\n",
    "c(x_train .labels)\n",
    "Counter({0: 996, 1: 1354, 2: 1019, 3: 275, 4: 475})\n",
    "Importing necessasry library\n",
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "Initializing The Model\n",
    "model = Sequential()\n",
    "Creating the model\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "classifier.summary()\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " flatten (Flatten)           (None, 6272)              0         \n",
    "                                                                 \n",
    " dense (Dense)               (None, 128)               802944    \n",
    "                                                                 \n",
    " dense_1 (Dense)             (None, 5)                 645       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 813,733\n",
    "Trainable params: 813,733\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Compiling the model\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "Fitting the model\n",
    "classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=10, validation_data=x_test,validation_steps = len(x_test))\n",
    "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
    "  This is separate from the ipykernel package so we can avoid doing imports until\n",
    "Epoch 1/10\n",
    "129/129 [==============================] - 1192s 9s/step - loss: 0.6981 - accuracy: 0.7312 - val_loss: 0.6113 - val_accuracy: 0.7470\n",
    "Epoch 2/10\n",
    "129/129 [==============================] - 39s 300ms/step - loss: 0.4519 - accuracy: 0.8267 - val_loss: 0.5630 - val_accuracy: 0.7761\n",
    "Epoch 3/10\n",
    "129/129 [==============================] - 37s 286ms/step - loss: 0.3904 - accuracy: 0.8536 - val_loss: 0.4508 - val_accuracy: 0.8224\n",
    "Epoch 4/10\n",
    "129/129 [==============================] - 37s 286ms/step - loss: 0.3631 - accuracy: 0.8653 - val_loss: 0.4773 - val_accuracy: 0.8181\n",
    "Epoch 5/10\n",
    "129/129 [==============================] - 37s 289ms/step - loss: 0.3238 - accuracy: 0.8755 - val_loss: 0.4213 - val_accuracy: 0.8407\n",
    "Epoch 6/10\n",
    "129/129 [==============================] - 38s 294ms/step - loss: 0.3063 - accuracy: 0.8844 - val_loss: 0.3872 - val_accuracy: 0.8558\n",
    "Epoch 7/10\n",
    "129/129 [==============================] - 39s 304ms/step - loss: 0.2774 - accuracy: 0.8934 - val_loss: 0.3918 - val_accuracy: 0.8579\n",
    "Epoch 8/10\n",
    "129/129 [==============================] - 37s 286ms/step - loss: 0.2752 - accuracy: 0.8937 - val_loss: 0.4671 - val_accuracy: 0.8256\n",
    "Epoch 9/10\n",
    "129/129 [==============================] - 37s 288ms/step - loss: 0.2678 - accuracy: 0.8992 - val_loss: 0.3788 - val_accuracy: 0.8515\n",
    "Epoch 10/10\n",
    "129/129 [==============================] - 37s 287ms/step - loss: 0.2651 - accuracy: 0.8980 - val_loss: 0.4373 - val_accuracy: 0.8310\n",
    "Saving the model\n",
    "classifier.save('nutrition.h5')\n",
    "Testing the Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img(\"/content/drive/MyDrive/ibm-nutrition-analyser/TEST_SET/APPLES/n07740461_9461.jpg\",target_size= (64,64))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "pred = classifier.predict(x)\n",
    "pred\n",
    "1/1 [==============================] - 0s 99ms/step\n",
    "array([[1., 0., 0., 0., 0.]], dtype=float32)\n",
    "index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
    "index[np.argmax(pred)]\n",
    "'APPLES'\n",
    "from flask import Flask,render_template,request\n",
    "# Flask-It is our framework which we are going to use to run/serve our application.\n",
    "#request-for accessing file which was uploaded by the user on our application.\n",
    "import os\n",
    "import numpy as np #used for numerical analysis\n",
    "from tensorflow.keras.models import load_model #to load our trained model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import requests\n",
    "app = Flask(__name__,template_folder=\"templates\") #initializing a flask app \n",
    "# Loading the model\n",
    "model=load_model('nutrition.h5')\n",
    "print(\"Loaded model from disk\")\n",
    "Loaded model from disk\n",
    "@ app.route('/')# route to display the home page\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "@ app.route('/image1', methods=['GET', 'POST']) # routes to the index html\n",
    "def image1():\n",
    "    return render_template(\"image.html\")\n",
    "@ app.route('/predict' ,methods=['GET','POST']) # route to show the predictions in a Web UI\n",
    "def lanuch():\n",
    "    if request.method=='POST':\n",
    "        f=request.files['file'] # requesting the file\n",
    "        basepath=os.path.dirname('__file__') #storing the file directory\n",
    "        filepath=os.path.join(basepath,\"uploads\",f.filename) #storing the file in uploads folder\n",
    "        f.save(filepath) #saving the file\n",
    "        \n",
    "        img=image.load_img(filepath,target_size=(64,64)) #load and reshaping the image\n",
    "        x=image.img_to_array(img) #converting image to an array\n",
    "        x=np.expand_dims(x,axis=0) #changing the dimensions of the image\n",
    "        \n",
    "        pred=np.argmax(model.predict(x), axis=1)\n",
    "        print(\"prediction\",pred) #printing the prediction\n",
    "        index=['APPLE','BANANA','ORANGE','PINEAPPLE','WATERMELON']\n",
    "        \n",
    "        result=str(index[pred[0]])\n",
    "        print(result)\n",
    "        x=result\n",
    "        result=nutrition(result)\n",
    "        print(result)\n",
    "        \n",
    "        return render_template(\"0.html\",showcase=(result),showcase1=(x))\n",
    "def nutrition(index):\n",
    "    \n",
    "    import requests\n",
    "\n",
    "    url = \"https://calorieninjas.p.rapidapi.com/v1/nutrition\"\n",
    "\n",
    "    querystring = {\"query\":index}\n",
    "\n",
    "    headers = {\n",
    "\t\"X-RapidAPI-Key\": \"85887549f4msh51e7315b280a87ep1f43e0jsn585c940f2ea6\",\n",
    "\t\"X-RapidAPI-Host\": \"calorieninjas.p.rapidapi.com\"\n",
    "     }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "    print(response.text)\n",
    "    return response.json()['items']\n",
    "if __name__ == \"__main__\":\n",
    "    # running the app\n",
    "    app.run(debug=False)\n",
    " * Serving Flask app \"__main__\" (lazy loading)\n",
    " * Environment: production\n",
    "   WARNING: This is a development server. Do not use it in a production deployment.\n",
    "   Use a production WSGI server instead.\n",
    " * Debug mode: off\n",
    "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
